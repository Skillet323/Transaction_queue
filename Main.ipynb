{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-22 10:15:16,760 - Loading data...\n",
      "2024-12-22 10:15:17,053 - Preprocessing providers...\n",
      "2024-12-22 10:15:17,083 - Providers processed with dynamic LIMIT_MIN and LIMIT_MAX updates.\n",
      "2024-12-22 10:15:17,084 - Creating or loading features...\n",
      "2024-12-22 10:15:22,134 - Loading model...\n",
      "2024-12-22 10:15:22,156 - Processing transactions and generating results...\n",
      "2024-12-22 10:29:13,093 - Results saved to results.csv\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from datetime import datetime\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from joblib import load\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(message)s\")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "FEATURES_FILE = \"features_test.csv\"\n",
    "LABELS_FILE = \"labels_test.npy\"\n",
    "RESULTS_FILE = \"results.csv\"\n",
    "MODEL_FILE = \"trained_model.joblib\"  # Path to the pre-trained model\n",
    "\n",
    "# Helper function: Safe datetime parsing\n",
    "def safe_parse_datetime(date_str: str) -> datetime:\n",
    "    try:\n",
    "        return datetime.fromisoformat(date_str)\n",
    "    except ValueError:\n",
    "        logger.error(f\"Invalid datetime format: {date_str}\")\n",
    "        return None\n",
    "\n",
    "# Preprocess providers with logic for dynamic LIMIT_MIN and LIMIT_MAX updates\n",
    "def preprocess_providers(providers: pd.DataFrame) -> pd.DataFrame:\n",
    "    if 'LIMIT_MIN' not in providers.columns or 'LIMIT_MAX' not in providers.columns:\n",
    "        logger.error(\"LIMIT_MIN or LIMIT_MAX column is missing in providers file.\")\n",
    "        raise KeyError(\"Missing required columns in providers data.\")\n",
    "\n",
    "    providers[\"TIME\"] = pd.to_datetime(providers[\"TIME\"])\n",
    "    providers = providers.sort_values(by=[\"ID\", \"TIME\"], ascending=[True, True])\n",
    "    grouped = providers.groupby([\"ID\", providers[\"TIME\"].dt.date])\n",
    "    updated_groups = []\n",
    "\n",
    "    for (provider_id, date), group in grouped:\n",
    "        earliest_row = group.iloc[0]\n",
    "        min_limit = earliest_row[\"LIMIT_MIN\"]\n",
    "        max_limit = earliest_row[\"LIMIT_MAX\"]\n",
    "        group[\"LIMIT_MIN\"] = min_limit\n",
    "        group[\"LIMIT_MAX\"] = max_limit\n",
    "        updated_groups.append(group)\n",
    "\n",
    "    updated_providers = pd.concat(updated_groups)\n",
    "    logger.info(\"Providers processed with dynamic LIMIT_MIN and LIMIT_MAX updates.\")\n",
    "    return updated_providers.reset_index(drop=True)\n",
    "\n",
    "def create_features(\n",
    "    providers: pd.DataFrame,\n",
    "    transactions: pd.DataFrame,\n",
    "    rate_dict: Dict[str, float],\n",
    "    features_file: str,\n",
    "    labels_file: str,\n",
    ") -> (pd.DataFrame, pd.Series):\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "\n",
    "    # Check if the user wants to regenerate features\n",
    "    regenerate = input(\"Do you want to regenerate features? (1 for yes, 0 for no): \").strip()\n",
    "    if regenerate == \"0\":\n",
    "        try:\n",
    "            # Attempt to load existing features\n",
    "            features = pd.read_csv(features_file)\n",
    "            labels = np.load(labels_file, allow_pickle=True)\n",
    "            all_features.extend(features.to_dict(orient=\"records\"))\n",
    "            all_labels.extend(labels)\n",
    "        except FileNotFoundError:\n",
    "            logger.error(\"Features or labels file not found. Regenerating features.\")\n",
    "            regenerate = \"1\"\n",
    "\n",
    "    if regenerate == \"1\":\n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            futures = [\n",
    "                executor.submit(process_transaction, transaction, providers, rate_dict)\n",
    "                for _, transaction in transactions.iterrows()\n",
    "            ]\n",
    "            for future in as_completed(futures):\n",
    "                features_and_labels = future.result()\n",
    "                if features_and_labels:\n",
    "                    features, labels = zip(*features_and_labels)\n",
    "                    all_features.extend(features)\n",
    "                    all_labels.extend(labels)\n",
    "\n",
    "        # Save newly generated features and labels\n",
    "        features_df = pd.DataFrame(all_features)\n",
    "        features_df.to_csv(features_file, index=False)\n",
    "        np.save(labels_file, all_labels)\n",
    "        logger.info(f\"Features saved to {features_file}\")\n",
    "        logger.info(f\"Labels saved to {labels_file}\")\n",
    "    else:\n",
    "        features_df = pd.DataFrame(all_features)\n",
    "\n",
    "    return features_df, pd.Series(all_labels)\n",
    "\n",
    "\n",
    "# Function to process a single transaction\n",
    "def process_transaction(transaction: pd.Series, providers: pd.DataFrame, rate_dict: Dict[str, float]) -> List[Dict[str, Any]]:\n",
    "    features = []\n",
    "    time_of_transaction = safe_parse_datetime(transaction[\"eventTimeRes\"])\n",
    "    if not time_of_transaction:\n",
    "        return []\n",
    "\n",
    "    transaction_amount_in_usd = transaction[\"amount\"] * rate_dict.get(transaction[\"cur\"], 1)\n",
    "\n",
    "    for _, provider in providers.iterrows():\n",
    "        if (transaction[\"amount\"] <= provider[\"LIMIT_MAX\"]\n",
    "            and provider[\"CURRENCY\"] == transaction[\"cur\"]\n",
    "            and transaction[\"amount\"] <= provider[\"MAX_SUM\"]\n",
    "            and transaction[\"amount\"] >= provider[\"MIN_SUM\"]):\n",
    "            \n",
    "            penalty = max(0, (provider[\"LIMIT_MIN\"] * 0.01))\n",
    "            success_score = ((provider[\"CONVERSION\"] > 0.5)\n",
    "                             + (provider[\"AVG_TIME\"] < 20)\n",
    "                             + (provider[\"COMMISSION\"] <= 0.04)\n",
    "                             + (penalty < 600)\n",
    "                             + (transaction_amount_in_usd <= 20))\n",
    "            \n",
    "            success = 1 if success_score >= 3 else 0\n",
    "            feature = {\n",
    "                \"conversion\": provider[\"CONVERSION\"],\n",
    "                \"avg_time\": provider[\"AVG_TIME\"],\n",
    "                \"commission\": provider[\"COMMISSION\"] * transaction[\"amount\"],\n",
    "                \"penalty\": penalty,\n",
    "                \"amount_in_usd\": transaction_amount_in_usd,\n",
    "                \"limits_ratio\": transaction[\"amount\"] / provider[\"LIMIT_MAX\"],\n",
    "                \"provider_id\": provider[\"ID\"],\n",
    "                \"transaction_id\": transaction.name,\n",
    "            }\n",
    "            features.append((feature, success))\n",
    "    return features\n",
    "\n",
    "# Updated function to predict flow and create chains\n",
    "def predict_flow(model, transaction, providers, rates, features_df) -> pd.DataFrame:\n",
    "    try:\n",
    "        results = []\n",
    "        transaction_features = features_df[features_df[\"transaction_id\"] == transaction.name].copy()\n",
    "        if transaction_features.empty:\n",
    "            return pd.DataFrame([{\"payment\": transaction[\"payment\"], \"chain\": \"Z\", \"status\": \"Failed\"}])\n",
    "\n",
    "        # Calculate probabilities and sort providers\n",
    "        transaction_features[\"probability\"] = model.predict_proba(\n",
    "            transaction_features[[\"conversion\", \"avg_time\", \"commission\", \"penalty\", \"amount_in_usd\"]]\n",
    "        )[:, 1]\n",
    "        sorted_features = transaction_features.sort_values(\"probability\", ascending=False)\n",
    "\n",
    "        chain = []\n",
    "        status = \"Failed\"\n",
    "        remaining_amount = transaction[\"amount\"]\n",
    "        for _, feature in sorted_features.iterrows():\n",
    "            provider_id = feature[\"provider_id\"]\n",
    "            chain.append(str(provider_id))\n",
    "\n",
    "            # Check provider limits and update dynamically\n",
    "            provider = providers.loc[providers[\"ID\"] == provider_id]\n",
    "            if provider.empty:\n",
    "                logger.warning(f\"No data found for provider ID {provider_id}.\")\n",
    "                continue\n",
    "\n",
    "            provider_idx = provider.index[0]\n",
    "            # Update provider's time by adding the average processing time\n",
    "            avg_time = providers.loc[provider_idx, \"AVG_TIME\"]\n",
    "            providers.loc[provider_idx, \"TIME\"] += pd.Timedelta(seconds=avg_time)\n",
    "            if (providers.loc[provider_idx, \"LIMIT_MAX\"] >= remaining_amount):\n",
    "                # Update provider limits dynamically\n",
    "                providers.loc[provider_idx, \"LIMIT_MAX\"] -= remaining_amount\n",
    "                providers.loc[provider_idx, \"LIMIT_MIN\"] -= remaining_amount\n",
    "                status = \"Captured\"\n",
    "                break\n",
    "        chain_str = \"-\".join(chain)\n",
    "        results.append({\n",
    "            \"payment\": transaction[\"payment\"],\n",
    "            \"chain\": chain_str if chain else \"Z\",\n",
    "            \"status\": status,\n",
    "        })\n",
    "\n",
    "        return pd.DataFrame(results)\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in predict_flow: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Main function\n",
    "def main(providers_file: str, payments_file: str, rates_file: str, features_file: str, labels_file: str):\n",
    "    try:\n",
    "        logger.info(\"Loading data...\")\n",
    "        providers = pd.read_csv(providers_file)\n",
    "        transactions = pd.read_csv(payments_file)\n",
    "        rates = pd.read_csv(rates_file).set_index(\"destination\").to_dict()[\"rate\"]\n",
    "\n",
    "        logger.info(\"Preprocessing providers...\")\n",
    "        providers = preprocess_providers(providers)\n",
    "\n",
    "        logger.info(\"Creating or loading features...\")\n",
    "        features_df, labels = create_features(providers, transactions, rates, features_file, labels_file)\n",
    "\n",
    "        logger.info(\"Loading model...\")\n",
    "        model = load(MODEL_FILE)\n",
    "\n",
    "        logger.info(\"Processing transactions and generating results...\")\n",
    "        all_results = []\n",
    "        for _, transaction in transactions.iterrows():\n",
    "            result = predict_flow(model, transaction, providers, rates, features_df)\n",
    "            all_results.append(result)\n",
    "\n",
    "        results_df = pd.concat(all_results, ignore_index=True)\n",
    "        results_df.to_csv(RESULTS_FILE, index=False)\n",
    "        logger.info(f\"Results saved to {RESULTS_FILE}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in main: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    providers_file = \"providers_2.csv\"\n",
    "    payments_file = \"payments_2.csv\"\n",
    "    rates_file = \"ex_rates.csv\"\n",
    "    main(providers_file, payments_file, rates_file, FEATURES_FILE, LABELS_FILE)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
