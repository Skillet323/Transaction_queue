{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-22 02:01:08,155 - Загрузка данных...\n",
      "2024-12-22 02:01:08,433 - Предобработка данных провайдеров...\n",
      "2024-12-22 02:01:08,463 - Providers processed with dynamic LIMIT_MIN and LIMIT_MAX updates based on the earliest time of each day.\n",
      "2024-12-22 02:01:08,469 - Генерация признаков и меток...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вы хотите сформировать новые признаки для данных?\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from datetime import datetime\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from joblib import load\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "FEATURES_FILE = \"features_test.csv\"\n",
    "LABELS_FILE = \"labels_test.npy\"\n",
    "RESULTS_FILE = \"results.csv\"\n",
    "MODEL_FILE = \"trained_model.joblib\"  # Path to the pre-trained model\n",
    "\n",
    "# Helper function: Safe datetime parsing\n",
    "def safe_parse_datetime(date_str: str) -> datetime:\n",
    "    try:\n",
    "        return datetime.fromisoformat(date_str)\n",
    "    except ValueError:\n",
    "        logger.error(f\"Invalid datetime format: {date_str}\")\n",
    "        return None\n",
    "\n",
    "# Preprocess providers with logic for dynamic LIMIT_MIN and LIMIT_MAX updates\n",
    "def preprocess_providers(providers: pd.DataFrame) -> pd.DataFrame:\n",
    "    providers['TIME'] = pd.to_datetime(providers['TIME'])\n",
    "    providers = providers.sort_values(by=['ID', 'TIME'], ascending=[True, True])\n",
    "    grouped = providers.groupby(['ID', providers['TIME'].dt.date])\n",
    "    updated_groups = []\n",
    "    \n",
    "    for (provider_id, date), group in grouped:\n",
    "        earliest_row = group.iloc[0]\n",
    "        min_limit = earliest_row['LIMIT_MIN']\n",
    "        max_limit = earliest_row['LIMIT_MAX']\n",
    "        group['LIMIT_MIN'] = min_limit\n",
    "        group['LIMIT_MAX'] = max_limit\n",
    "        updated_groups.append(group)\n",
    "        \n",
    "    updated_providers = pd.concat(updated_groups)\n",
    "    logger.info(\"Providers processed with dynamic LIMIT_MIN and LIMIT_MAX updates based on the earliest time of each day.\")\n",
    "    return updated_providers.reset_index(drop=True)\n",
    "\n",
    "# Function to process a single transaction and generate features for it\n",
    "def process_transaction(transaction: pd.Series, providers: pd.DataFrame, rate_dict: Dict[str, float]) -> (List[Dict[str, Any]], List[int]):\n",
    "    features = []\n",
    "    labels = []\n",
    "    providers_compatible = []\n",
    "    ids = []\n",
    "    time_of_transaction = safe_parse_datetime(transaction['eventTimeRes'])\n",
    "    time_of_transaction_seconds = (time_of_transaction.year * 365 + time_of_transaction.month * 30 + time_of_transaction.day) * 86400 + time_of_transaction.hour * 3600 + time_of_transaction.minute * 60 + time_of_transaction.second\n",
    "    transaction_amount_in_usd = transaction['amount'] * rate_dict.get(transaction['cur'], 1)\n",
    "    \n",
    "    for _, provider in providers.iterrows():\n",
    "        t = provider['TIME']\n",
    "        t_seconds = (t.year * 365 + t.month * 30 + t.day) * 86400 + t.hour * 3600 + t.minute * 60 + t.second\n",
    "        \n",
    "        if (transaction['amount'] <= provider['LIMIT_MAX'] and\n",
    "            provider['CURRENCY'] == transaction['cur'] and\n",
    "            transaction['amount'] <= provider['MAX_SUM'] and\n",
    "            transaction['amount'] >= provider['MIN_SUM'] and\n",
    "            time_of_transaction_seconds - t_seconds >= 0):\n",
    "            if provider['ID'] not in ids:\n",
    "                providers_compatible.append(provider)\n",
    "                ids.append(provider['ID'])\n",
    "                \n",
    "    for provider in providers_compatible:\n",
    "        penalty = max(0, (provider['LIMIT_MIN']) * 0.01)\n",
    "        time_of_day = time_of_transaction.hour\n",
    "        day_of_week = time_of_transaction.weekday()\n",
    "        is_weekend = 1 if day_of_week >= 5 else 0\n",
    "        success_score = ((provider['CONVERSION'] > 0.5) + (provider['AVG_TIME'] < 20) + (provider['COMMISSION'] <= 0.04) + (penalty < 600) + (transaction_amount_in_usd <= 20))\n",
    "        success = 1 if success_score >= 3 else 0\n",
    "        \n",
    "        feature = {\n",
    "            'conversion': provider['CONVERSION'],\n",
    "            'avg_time': provider['AVG_TIME'],\n",
    "            'commission': provider['COMMISSION'] * transaction['amount'],\n",
    "            'penalty': penalty,\n",
    "            'amount_in_usd': transaction_amount_in_usd,\n",
    "            'limits_ratio': transaction['amount'] / provider['LIMIT_MAX'],\n",
    "            'provider_id': provider['ID'],\n",
    "            'transaction_id': transaction.name,\n",
    "            'eventTimeRes': transaction['eventTimeRes'],\n",
    "            'time_in_seconds': time_of_transaction_seconds,\n",
    "            'time_of_day': time_of_day,\n",
    "            'day_of_week': day_of_week,\n",
    "            'is_weekend': is_weekend\n",
    "        }\n",
    "        features.append(feature)\n",
    "        labels.append(success)\n",
    "        \n",
    "    return features, labels\n",
    "\n",
    "# Create features for each provider-transaction pair, along with the corresponding labels (success/failure)\n",
    "def create_features(providers: pd.DataFrame, transactions: pd.DataFrame, rate_dict: Dict[str, float], features_file: str, labels_file: str) -> (pd.DataFrame, pd.Series):\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    \n",
    "    print(\"Вы хотите сформировать новые признаки для данных?\")\n",
    "    a = int(input(\"1 - да, 0 - нет (использовать имеющиеся, если есть):\"))\n",
    "    \n",
    "    if a == 0:\n",
    "        try:\n",
    "            features = pd.read_csv(features_file)\n",
    "            labels = np.load(labels_file, allow_pickle=True)\n",
    "            all_features.extend(features.to_dict(orient='records'))\n",
    "            all_labels.extend(labels)\n",
    "        except FileNotFoundError:\n",
    "            logger.error(\"Features or labels file not found, generating new ones.\")\n",
    "            a = 1\n",
    "    \n",
    "    if a == 1:\n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            futures = [executor.submit(process_transaction, transaction, providers, rate_dict) for _, transaction in transactions.iterrows()]\n",
    "            for future in as_completed(futures):\n",
    "                features, labels = future.result()\n",
    "                all_features.extend(features)\n",
    "                all_labels.extend(labels)\n",
    "    \n",
    "    features_df = pd.DataFrame(all_features)\n",
    "    features_df.to_csv(features_file, index=False)\n",
    "    np.save(labels_file, all_labels)\n",
    "    logger.info(f\"Features saved to {features_file}\")\n",
    "    logger.info(f\"Labels saved to {labels_file}\")\n",
    "    return features_df, pd.Series(all_labels)\n",
    "\n",
    "# Load data from CSV files\n",
    "def load_data(providers_file: str, payments_file: str, rates_file: str) -> (pd.DataFrame, pd.DataFrame, Dict[str, float]):\n",
    "    providers = pd.read_csv(providers_file)\n",
    "    transactions = pd.read_csv(payments_file)\n",
    "    rates = pd.read_csv(rates_file).set_index('destination').to_dict()['rate']\n",
    "    return providers, transactions, rates\n",
    "\n",
    "\n",
    "# Обновленная функция main\n",
    "def main(providers_file: str, payments_file: str, rates_file: str, features_for_model: str, labels_for_model: str):\n",
    "    try:\n",
    "        logger.info(\"Загрузка данных...\")\n",
    "        providers, transactions, rates = load_data(providers_file, payments_file, rates_file)\n",
    "        logger.debug(f\"Провайдеры загружены: {len(providers)} записей\")\n",
    "        logger.debug(f\"Транзакции загружены: {len(transactions)} записей\")\n",
    "        logger.debug(f\"Курсы валют: {rates}\")\n",
    "\n",
    "        logger.info(\"Предобработка данных провайдеров...\")\n",
    "        providers = preprocess_providers(providers)\n",
    "        logger.debug(f\"Обработанные провайдеры: {providers.head()}\")\n",
    "\n",
    "        logger.info(\"Генерация признаков и меток...\")\n",
    "        features_df, labels = create_features(providers, transactions, rates, features_for_model, labels_for_model)\n",
    "        logger.debug(f\"Генерированные признаки: {features_df.shape}\")\n",
    "        logger.debug(f\"Пример первых признаков: {features_df.head()}\")\n",
    "\n",
    "        logger.info(\"Загрузка модели...\")\n",
    "        model = load(MODEL_FILE)\n",
    "        logger.debug(f\"Модель загружена из {MODEL_FILE}\")\n",
    "\n",
    "        logger.info(\"Выполнение предсказаний для всех транзакций...\")\n",
    "        predictions = model.predict(features_df[[\"conversion\", \"avg_time\", \"commission\", \"penalty\", \"amount_in_usd\"]])\n",
    "        probabilities = model.predict_proba(features_df[[\"conversion\", \"avg_time\", \"commission\", \"penalty\", \"amount_in_usd\"]])[:, 1]\n",
    "        logger.debug(f\"Предсказания: {predictions}\")\n",
    "        logger.debug(f\"Вероятности: {probabilities}\")\n",
    "\n",
    "        logger.info(\"Начало обработки транзакций через predict_flow...\")\n",
    "        results = []\n",
    "        for idx, transaction in transactions.iterrows():\n",
    "            logger.debug(f\"Обработка транзакции ID {transaction.name}...\")\n",
    "            result = predict_flow(model, transaction, providers, rates, features_df)\n",
    "            results.append(result)\n",
    "\n",
    "        logger.info(\"Сохранение результатов...\")\n",
    "        results_df = pd.concat(results, ignore_index=True)\n",
    "        results_df.to_csv(RESULTS_FILE, index=False)\n",
    "        logger.info(f\"Результаты сохранены в {RESULTS_FILE}\")\n",
    "\n",
    "        return predictions, probabilities, results_df\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Ошибка в main: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "# Обновленная функция predict_flow\n",
    "def predict_flow(model, transaction, providers, rates, features_df, results_file=\"results.csv\") -> pd.DataFrame:\n",
    "    try:\n",
    "        logger.debug(f\"Начало обработки транзакции {transaction.name}...\")\n",
    "\n",
    "        results = []\n",
    "        transaction_features = features_df[features_df['transaction_id'] == transaction.name]\n",
    "        if transaction_features.empty:\n",
    "            logger.warning(f\"Нет признаков для транзакции ID {transaction.name}.\")\n",
    "            results.append({\n",
    "                'terminal_id': 'Z',\n",
    "                'eventTimeRes': transaction['eventTimeRes'],\n",
    "                'prediction': '-',\n",
    "                'amount_in_usd': -1\n",
    "            })\n",
    "            return pd.DataFrame(results)\n",
    "\n",
    "        logger.debug(f\"Найдено {len(transaction_features)} признаков для транзакции ID {transaction.name}.\")\n",
    "        predicted_success = model.predict(transaction_features[[\"conversion\", \"avg_time\", \"commission\", \"penalty\", \"amount_in_usd\"]])\n",
    "        logger.debug(f\"Предсказанный результат: {predicted_success}\")\n",
    "\n",
    "        for _, feature_row in transaction_features.iterrows():\n",
    "            terminal_id = feature_row['provider_id']\n",
    "            amount_in_usd = feature_row['amount_in_usd']\n",
    "            logger.debug(f\"Обработка провайдера ID {terminal_id}...\")\n",
    "\n",
    "            matching_provider = providers[providers['ID'] == terminal_id]\n",
    "            if matching_provider.empty:\n",
    "                logger.warning(f\"Нет данных о провайдере ID {terminal_id}.\")\n",
    "                continue\n",
    "\n",
    "            current_time_dt = pd.to_datetime(matching_provider['TIME'].values[0])\n",
    "            event_time_res_dt = pd.to_datetime(transaction['eventTimeRes'])\n",
    "\n",
    "            logger.debug(f\"Текущая дата провайдера: {current_time_dt}, дата транзакции: {event_time_res_dt}\")\n",
    "\n",
    "            if pd.isna(current_time_dt) or pd.isna(event_time_res_dt):\n",
    "                logger.warning(f\"Некорректные даты для провайдера ID {terminal_id} или транзакции.\")\n",
    "                continue\n",
    "\n",
    "            if current_time_dt.date() == event_time_res_dt.date():\n",
    "                logger.debug(\"Совпадение дат найдено.\")\n",
    "\n",
    "                if predicted_success[0] == 1:\n",
    "                    logger.debug(\"Обновление лимитов провайдера после успешной транзакции.\")\n",
    "                    providers.loc[providers['ID'] == terminal_id, 'MIN_LIMITS'] -= amount_in_usd\n",
    "                    providers.loc[providers['ID'] == terminal_id, 'MAX_LIMITS'] -= amount_in_usd\n",
    "\n",
    "                avg_time = matching_provider['AVG_TIME'].values[0]\n",
    "                providers.loc[providers['ID'] == terminal_id, 'TIME'] += pd.Timedelta(seconds=avg_time)\n",
    "                \n",
    "                results.append({\n",
    "                    'terminal_id': terminal_id,\n",
    "                    'eventTimeRes': transaction['eventTimeRes'],\n",
    "                    'prediction': int(predicted_success[0]),\n",
    "                    'amount_in_usd': amount_in_usd\n",
    "                })\n",
    "                logger.debug(f\"Результат добавлен: {results[-1]}\")\n",
    "\n",
    "        results_df = pd.DataFrame(results)\n",
    "        logger.info(f\"Результаты транзакции {transaction.name} сохранены.\")\n",
    "        return results_df\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Ошибка в predict_flow: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Пример использования\n",
    "    providers_file = \"providers_2.csv\"\n",
    "    payments_file = \"payments_2.csv\"\n",
    "    rates_file = \"ex_rates.csv\"\n",
    "    \n",
    "    features_for_model = FEATURES_FILE\n",
    "    labels_for_model = LABELS_FILE\n",
    "    main(providers_file, payments_file, rates_file, features_for_model, labels_for_model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
